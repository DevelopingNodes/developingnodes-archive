{
    "status": "ok",
    "feed": {
        "url": "https://medium.com/feed/@sonujose993",
        "title": "Stories by Sonu Jose on Medium",
        "link": "https://medium.com/@sonujose993?source=rss-e9f19c1a98fb------2",
        "author": "",
        "description": "Stories by Sonu Jose on Medium",
        "image": "https://cdn-images-1.medium.com/fit/c/150/150/1*6o9-QJAw8nAAfrdFP1Sg-g.jpeg"
    },
    "items": [
        {
            "title": "How to manage Terraform state in Azure Blob Storage",
            "pubDate": "2019-08-25 13:37:48",
            "link": "https://medium.com/faun/how-to-manage-terraform-state-in-azure-blob-storage-870a80917450?source=rss-e9f19c1a98fb------2",
            "guid": "https://medium.com/p/870a80917450",
            "author": "Sonu Jose",
            "thumbnail": "https://cdn-images-1.medium.com/max/1024/0*M55eo7H9wUxQ6HB_",
            "description": "\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*M55eo7H9wUxQ6HB_\"><figcaption>Photo by <a href=\"https://unsplash.com/@chrispanas?utm_source=medium&amp;utm_medium=referral\">chris panas</a> on\u00a0<a href=\"https://unsplash.com/?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p>Every time you ran <strong>terraform plan or terraform apply,</strong> Terraform was able to find the resources it created previously and update them accordingly. But how did Terraform know which resources it was supposed to\u00a0manage?</p>\n<p>Whenever you run terraform apply it creates a file in your working directory called <strong>terraform.tfstate</strong>. The State is an essential building block of every Terraform project.<em> It will act as a kind of database for the configuration of your terraform project. Terraform uses this local state to create plans and make changes to your infrastructure.</em> Prior to any operation, Terraform does a refresh to update the state with the real infrastructure.</p>\n<p>This is how a tfstate file looks like. In this state I have just created a new resource group in\u00a0Azure.</p>\n<a href=\"https://medium.com/media/4ab9eeb39a74d75f817b3a37469501cf/href\">https://medium.com/media/4ab9eeb39a74d75f817b3a37469501cf/href</a><h4>Terraform workflow</h4>\n<p>This diagram explains the simple workflow of terraform. The\u00a0.tfstate file is created after the execution plan is executed to Azure resources. Terraform destroy command will destroy the Terraform-managed infrastructure, that too terraform understands from the\u00a0.tfstate\u00a0file.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*kiExEpyPOJdwjvHBKw7AZw.png\"></figure><h4>Why state needs to be managed and\u00a0locked?</h4>\n<p>It might be okay if you are running a demo, just trying something out or just getting started with terraform. However, in real world scenario this is not the case. Because your laptop might not be the truth for terraform, If a colleague now ran terraform plan against the same code base from their laptop the output would be most likely incorrect.</p>\n<p>Terraform also creates a file lock on the state file when running terraform apply which prevents other terraform executions to take place against this state file. With local state this will not work, potentially resulting in multiple processes executing at the same\u00a0time.</p>\n<h4>Introducing Terraform Backend</h4>\n<p>Terraform Backends determine where state is stored. For example, the local (default) backend stores state in a local JSON file on disk. The Consul backend stores the state within Consul. Both of these backends happen to provide locking: local via system APIs and Consul via locking APIs. There are a number of supporters for backend\u200a\u2014\u200as3, artifactory, azurerm, consul, etcd, etcdv3, gcs, http, manta, terraform enterprise etc..</p>\n<p>In this article we will be using <strong>Azurerm</strong> as the backend. It Stores the state as a Blob with the given Key within the Blob Container within the <strong>Azure Blob Storage Account</strong>. This backend also supports state locking and consistency checking via native capabilities of Azure Blob\u00a0Storage.</p>\n<p><strong>Lets see how can we manage Terraform state using Azure Blob\u00a0\u2026</strong></p>\n<h4><strong>Create a Storage\u00a0Account</strong></h4>\n<p>Here I am using azure CLI to create azure storage account and container.</p>\n<a href=\"https://medium.com/media/0838ca9622575cc1b89625b623d13a02/href\">https://medium.com/media/0838ca9622575cc1b89625b623d13a02/href</a><h4><strong>Configure State\u00a0Backend</strong></h4>\n<p>Now we have an instance of <em>Azure Blob Storage</em> being available somewhere in the cloud; Different authentication mechanisms can be used to connect Azure Storage Container to the terraform backend\u200a\u2014\u200aAzure CLI or Service Principal, Managed Service Identity, Storage Account Access Key, Storage Account associated SAS\u00a0Token.</p>\n<ol><li>Using Service Principal</li></ol>\n<pre>terraform {   <br> backend \"azurerm\" {     <br> storage_account_name  = \"tstate09762\"     <br> container_name        = \"tstate\"     <br> key                   = \"terraform.tfstate\"   <br> } <br>}</pre>\n<p>2. Using Managed Service\u00a0Identity</p>\n<pre>terraform {   <br> backend \"azurerm\" {     <br> storage_account_name  = \"tstate09762\"     <br> container_name        = \"tstate\"     <br> key                   = \"terraform.tfstate\"<br> use_msi               <strong>=</strong> <strong>true</strong><br> subscription_id       <strong>=</strong> \"00000000-0000-0000-0000-000000000000\"<br> tenant_id             <strong>=</strong> \"00000000-0000-0000-0000-000000000000\"   <br> } <br>}</pre>\n<p>If the Backend is configured, you can execute terraform apply once again. <em>Terraform</em> will ask if you want to push the existing (local) state to the new backend and overwrite potential existing remote state. After answering the question with yes, you\u2019ll end up having your project migrated to rely on <em>Remote\u00a0State</em>.</p>\n<p>The backends key property specifies the name of the Blob in the <em>Azure Blob Storage Container</em> which is again configurable by the container_name property.</p>\n<h4><strong>State Locking</strong></h4>\n<p>State locking is used to control write-operations on the state and to ensure that only one process modifies the state at one point in time. Not all <em>State Backends</em> support state locking. Luckily it\u2019s supported for <em>Azure Blob Storage</em> by using the previously referenced <em>Azure Blob Storage Lease</em> mechanism. State locking is applied automatically by <em>Terraform</em>.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/579/1*n8Tf6GsIYVYqpQWdNKKJ-A.png\"></figure><h4>Manage versions with snapshots</h4>\n<p>Blob storage service has the ability to create snapshots of the blobs that can be used for tracking changes done on a blob over different periods of time. Snapshots provide an automatic and free versioning mechanism. Using snapshots, you can rollback any changes done on a blob to a specific point in time or even to the original blob. Using this feature you can manage the version of your state\u00a0file.</p>\n<p>You can still manually retrieve the state from the remote state using the terraform state pull command. This will load your remote state and output it to stdout. You can choose to save that to a file or perform any other operations.</p>\n<h4>Useful Links</h4>\n<p>Terraform <a href=\"https://www.terraform.io/docs/state/index.html\">state docs</a>, <a href=\"https://www.terraform.io/docs/backends/index.html\">backend docs</a>, <a href=\"https://www.terraform.io/docs/backends/types/azurerm.html\">backends: azurerm</a></p>\n<p><a href=\"https://www.slideshare.net/mithunshanbhag/terraform-on-azure-166063069\">https://www.slideshare.net/mithunshanbhag/terraform-on-azure-166063069</a></p>\n<p>If you are new to Terraform and IaC you can start with\u200a\u2014\u200a<a href=\"https://medium.com/faun/getting-started-with-terraform-and-infrastructure-as-code-2e429e9a2277\">Getting Started with Terraform and Infrastructure as\u00a0Code</a></p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/727/0*Piks8Tu6xUYpF4DU\"></figure><p><strong>Follow us on </strong><a href=\"https://twitter.com/joinfaun\"><strong>Twitter</strong></a><strong> </strong>\ud83d\udc26<strong> and </strong><a href=\"https://www.facebook.com/faun.dev/\"><strong>Facebook</strong></a><strong> </strong>\ud83d\udc65<strong> and join our </strong><a href=\"https://www.facebook.com/groups/364904580892967/\"><strong>Facebook Group</strong></a><strong>\u00a0</strong>\ud83d\udcac<strong>.</strong></p>\n<p><strong>To join our community Slack </strong>\ud83d\udde3\ufe0f <strong>and read our weekly Faun topics </strong>\ud83d\uddde\ufe0f,<strong> click\u00a0here\u2b07</strong></p>\n<figure><a href=\"https://www.faun.dev/join/?utm_source=medium.com%2Ffaun&amp;utm_medium=medium&amp;utm_campaign=faunmediumbanner\"><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*oSdFkACJxs5iy1oR\"></a></figure><h4>If this post was helpful, please click the clap \ud83d\udc4f button below a few times to show your support for the author!\u00a0\u2b07</h4>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=870a80917450\" width=\"1\" height=\"1\"><hr>\n<p><a href=\"https://medium.com/faun/how-to-manage-terraform-state-in-azure-blob-storage-870a80917450\">How to manage Terraform state in Azure Blob Storage</a> was originally published in <a href=\"https://medium.com/faun\">Faun</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
            "content": "\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*M55eo7H9wUxQ6HB_\"><figcaption>Photo by <a href=\"https://unsplash.com/@chrispanas?utm_source=medium&amp;utm_medium=referral\">chris panas</a> on\u00a0<a href=\"https://unsplash.com/?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p>Every time you ran <strong>terraform plan or terraform apply,</strong> Terraform was able to find the resources it created previously and update them accordingly. But how did Terraform know which resources it was supposed to\u00a0manage?</p>\n<p>Whenever you run terraform apply it creates a file in your working directory called <strong>terraform.tfstate</strong>. The State is an essential building block of every Terraform project.<em> It will act as a kind of database for the configuration of your terraform project. Terraform uses this local state to create plans and make changes to your infrastructure.</em> Prior to any operation, Terraform does a refresh to update the state with the real infrastructure.</p>\n<p>This is how a tfstate file looks like. In this state I have just created a new resource group in\u00a0Azure.</p>\n<a href=\"https://medium.com/media/4ab9eeb39a74d75f817b3a37469501cf/href\">https://medium.com/media/4ab9eeb39a74d75f817b3a37469501cf/href</a><h4>Terraform workflow</h4>\n<p>This diagram explains the simple workflow of terraform. The\u00a0.tfstate file is created after the execution plan is executed to Azure resources. Terraform destroy command will destroy the Terraform-managed infrastructure, that too terraform understands from the\u00a0.tfstate\u00a0file.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*kiExEpyPOJdwjvHBKw7AZw.png\"></figure><h4>Why state needs to be managed and\u00a0locked?</h4>\n<p>It might be okay if you are running a demo, just trying something out or just getting started with terraform. However, in real world scenario this is not the case. Because your laptop might not be the truth for terraform, If a colleague now ran terraform plan against the same code base from their laptop the output would be most likely incorrect.</p>\n<p>Terraform also creates a file lock on the state file when running terraform apply which prevents other terraform executions to take place against this state file. With local state this will not work, potentially resulting in multiple processes executing at the same\u00a0time.</p>\n<h4>Introducing Terraform Backend</h4>\n<p>Terraform Backends determine where state is stored. For example, the local (default) backend stores state in a local JSON file on disk. The Consul backend stores the state within Consul. Both of these backends happen to provide locking: local via system APIs and Consul via locking APIs. There are a number of supporters for backend\u200a\u2014\u200as3, artifactory, azurerm, consul, etcd, etcdv3, gcs, http, manta, terraform enterprise etc..</p>\n<p>In this article we will be using <strong>Azurerm</strong> as the backend. It Stores the state as a Blob with the given Key within the Blob Container within the <strong>Azure Blob Storage Account</strong>. This backend also supports state locking and consistency checking via native capabilities of Azure Blob\u00a0Storage.</p>\n<p><strong>Lets see how can we manage Terraform state using Azure Blob\u00a0\u2026</strong></p>\n<h4><strong>Create a Storage\u00a0Account</strong></h4>\n<p>Here I am using azure CLI to create azure storage account and container.</p>\n<a href=\"https://medium.com/media/0838ca9622575cc1b89625b623d13a02/href\">https://medium.com/media/0838ca9622575cc1b89625b623d13a02/href</a><h4><strong>Configure State\u00a0Backend</strong></h4>\n<p>Now we have an instance of <em>Azure Blob Storage</em> being available somewhere in the cloud; Different authentication mechanisms can be used to connect Azure Storage Container to the terraform backend\u200a\u2014\u200aAzure CLI or Service Principal, Managed Service Identity, Storage Account Access Key, Storage Account associated SAS\u00a0Token.</p>\n<ol><li>Using Service Principal</li></ol>\n<pre>terraform {   <br> backend \"azurerm\" {     <br> storage_account_name  = \"tstate09762\"     <br> container_name        = \"tstate\"     <br> key                   = \"terraform.tfstate\"   <br> } <br>}</pre>\n<p>2. Using Managed Service\u00a0Identity</p>\n<pre>terraform {   <br> backend \"azurerm\" {     <br> storage_account_name  = \"tstate09762\"     <br> container_name        = \"tstate\"     <br> key                   = \"terraform.tfstate\"<br> use_msi               <strong>=</strong> <strong>true</strong><br> subscription_id       <strong>=</strong> \"00000000-0000-0000-0000-000000000000\"<br> tenant_id             <strong>=</strong> \"00000000-0000-0000-0000-000000000000\"   <br> } <br>}</pre>\n<p>If the Backend is configured, you can execute terraform apply once again. <em>Terraform</em> will ask if you want to push the existing (local) state to the new backend and overwrite potential existing remote state. After answering the question with yes, you\u2019ll end up having your project migrated to rely on <em>Remote\u00a0State</em>.</p>\n<p>The backends key property specifies the name of the Blob in the <em>Azure Blob Storage Container</em> which is again configurable by the container_name property.</p>\n<h4><strong>State Locking</strong></h4>\n<p>State locking is used to control write-operations on the state and to ensure that only one process modifies the state at one point in time. Not all <em>State Backends</em> support state locking. Luckily it\u2019s supported for <em>Azure Blob Storage</em> by using the previously referenced <em>Azure Blob Storage Lease</em> mechanism. State locking is applied automatically by <em>Terraform</em>.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/579/1*n8Tf6GsIYVYqpQWdNKKJ-A.png\"></figure><h4>Manage versions with snapshots</h4>\n<p>Blob storage service has the ability to create snapshots of the blobs that can be used for tracking changes done on a blob over different periods of time. Snapshots provide an automatic and free versioning mechanism. Using snapshots, you can rollback any changes done on a blob to a specific point in time or even to the original blob. Using this feature you can manage the version of your state\u00a0file.</p>\n<p>You can still manually retrieve the state from the remote state using the terraform state pull command. This will load your remote state and output it to stdout. You can choose to save that to a file or perform any other operations.</p>\n<h4>Useful Links</h4>\n<p>Terraform <a href=\"https://www.terraform.io/docs/state/index.html\">state docs</a>, <a href=\"https://www.terraform.io/docs/backends/index.html\">backend docs</a>, <a href=\"https://www.terraform.io/docs/backends/types/azurerm.html\">backends: azurerm</a></p>\n<p><a href=\"https://www.slideshare.net/mithunshanbhag/terraform-on-azure-166063069\">https://www.slideshare.net/mithunshanbhag/terraform-on-azure-166063069</a></p>\n<p>If you are new to Terraform and IaC you can start with\u200a\u2014\u200a<a href=\"https://medium.com/faun/getting-started-with-terraform-and-infrastructure-as-code-2e429e9a2277\">Getting Started with Terraform and Infrastructure as\u00a0Code</a></p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/727/0*Piks8Tu6xUYpF4DU\"></figure><p><strong>Follow us on </strong><a href=\"https://twitter.com/joinfaun\"><strong>Twitter</strong></a><strong> </strong>\ud83d\udc26<strong> and </strong><a href=\"https://www.facebook.com/faun.dev/\"><strong>Facebook</strong></a><strong> </strong>\ud83d\udc65<strong> and join our </strong><a href=\"https://www.facebook.com/groups/364904580892967/\"><strong>Facebook Group</strong></a><strong>\u00a0</strong>\ud83d\udcac<strong>.</strong></p>\n<p><strong>To join our community Slack </strong>\ud83d\udde3\ufe0f <strong>and read our weekly Faun topics </strong>\ud83d\uddde\ufe0f,<strong> click\u00a0here\u2b07</strong></p>\n<figure><a href=\"https://www.faun.dev/join/?utm_source=medium.com%2Ffaun&amp;utm_medium=medium&amp;utm_campaign=faunmediumbanner\"><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*oSdFkACJxs5iy1oR\"></a></figure><h4>If this post was helpful, please click the clap \ud83d\udc4f button below a few times to show your support for the author!\u00a0\u2b07</h4>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=870a80917450\" width=\"1\" height=\"1\"><hr>\n<p><a href=\"https://medium.com/faun/how-to-manage-terraform-state-in-azure-blob-storage-870a80917450\">How to manage Terraform state in Azure Blob Storage</a> was originally published in <a href=\"https://medium.com/faun\">Faun</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
            "enclosure": {},
            "categories": [
                "devops",
                "terraform",
                "software-engineering",
                "azure",
                "software-development"
            ]
        },
        {
            "title": "Getting Started with Terraform and Infrastructure as Code",
            "pubDate": "2019-08-04 18:14:17",
            "link": "https://medium.com/faun/getting-started-with-terraform-and-infrastructure-as-code-2e429e9a2277?source=rss-e9f19c1a98fb------2",
            "guid": "https://medium.com/p/2e429e9a2277",
            "author": "Sonu Jose",
            "thumbnail": "https://cdn-images-1.medium.com/max/1024/0*g_gzQiegpNUliVRZ",
            "description": "\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*g_gzQiegpNUliVRZ\"><figcaption>Photo by <a href=\"https://unsplash.com/@_m_v_?utm_source=medium&amp;utm_medium=referral\">_M_V_</a> on\u00a0<a href=\"https://unsplash.com/?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p>Why do people really cares about Infrastructure Management/Automation? Before answering the question, lets start with this\u00a0: <em>How is infrastructure traditionally managed?</em></p>\n<p>In early ages I\u2019m a consumer of infrastructure, I would file a ticket, and then someone on the other end of this ticketing queue is pulling it off, logging it into a management portal or an administrative console, and pointing and clicking to provision that piece of infrastructure.</p>\n<p>This is fine provided the requirements are minimal. What if it comes to more complex requirements in multiple environments?</p>\n<blockquote>Infrastructure as Code evolved to solve the problem of <em>environment drift</em> in the release pipeline. Without IaC, teams must maintain the settings of individual deployment environments.</blockquote>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/600/1*gI7nYpjtjhiGChbOwuxZVA.png\"><figcaption>Infrastructure as Code\u00a0(IaC)</figcaption></figure><p>Lets conclude the benefits\u00a0as..</p>\n<ul>\n<li>Infrastructure as Code enables DevOps teams to test applications in production-like environments early in the development cycle.</li>\n<li>You can repeatedly deploy your solution throughout the development lifecycle and have confidence your resources are deployed in a consistent state.</li>\n<li>You can define the dependencies between resources so they\u2019re deployed in the correct\u00a0order.</li>\n</ul>\n<h4>Here comes Terraform\u2026</h4>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/472/1*rmwpOy4OtvgVz3yJvBetuQ.png\"><figcaption>Terraform</figcaption></figure><blockquote>Terraform is an opensource tool that codifies APIs into declarative configuration files that can be shared among team members, treated as code, edited, reviewed, and versioned.</blockquote>\n<p>For one, the configuration management tools, like Chef and Puppet, Terraform uses provisioners to set up resources, such as network, instances, and other things within the cloud platform. Since Terraform operates at this higher, abstract level than the other platforms, it provides a way for Terraform to work alongside or in place of those other\u00a0tools.</p>\n<h4>Terraform Approach</h4>\n<p>It gives it the ability, as a very lightweight executable, to take the place of any of the other ones, or simply work within the pipeline of a Chef automation, or a Puppet automation, of infrastructure. In relation to CloudFormation, the differences start out with cross platform and multi-cloud platform capabilities being a strong point in Terraform and relatively impossible to do multi-cloud in ARM Templates, because it\u2019s a propriety Azure only infrastructure tool.</p>\n<p>Heterogeneous infrastructure, frequently provisioned, short lived, and automated provisioning on-demand.</p>\n<ul>\n<li>Infrastructure as\u00a0code</li>\n<li>Embrace diversity with providers</li>\n<li>Enable self-service infrastructure</li>\n</ul>\n<p><strong>A quick look into Terraform workflow</strong></p>\n<p>The terraform <strong>Providers</strong> leverage infrastructure specific API to preserve unique capability for each providers. All these are unique and distinct.<em> It also comes up with custom resources for every cloud, but single consistent workflow to manage multiple cloud and services.</em></p>\n<p>The code given below is in HashiCorp Configuration Language (HCL). HCL is a structured language created with DevOps in mind; it is machine-friendly yet easy for humans to read, and it supports comments.</p>\n<a href=\"https://medium.com/media/dead3812189592313f0e9402a3625860/href\">https://medium.com/media/dead3812189592313f0e9402a3625860/href</a><p>The provider block is used to configure the named provider, in this instance the <a href=\"https://www.terraform.io/docs/providers/azurerm/index.html\">Azure provider</a>(azurerm). The Azure provider is responsible for creating and managing resources on\u00a0Azure.</p>\n<p>The <strong>terraform resource</strong> block defines a resource that exists within the infrastructure. A resource might be a physical component such as a network interface, or it can be a logical resource such as a Heroku application.</p>\n<a href=\"https://medium.com/media/a043ddd03d23c5882d275f2dde2c7b64/href\">https://medium.com/media/a043ddd03d23c5882d275f2dde2c7b64/href</a><p>The first command to run for a new configuration is terraform init, which initializes various local settings and data that will be used by subsequent commands. The terraform plan command is used to create an execution plan. Terraform performs a refresh, unless explicitly disabled, and then determines what actions are necessary to achieve the desired state specified in the configuration files.</p>\n<p>Next command terraform apply will shows the execution plan, describing which actions Terraform will take in order to change real infrastructure to match the configuration. The output format is similar to the diff format generated by tools such as Git. If the plan was created successfully, Terraform will now pause and wait for approval before proceeding.</p>\n<pre>sonu.jose@Azure:~/test$ terraform apply</pre>\n<pre>An execution plan has been generated and is shown below.<br>Resource actions are indicated with the following symbols:<br>  + create</pre>\n<pre>Terraform will perform the following actions:</pre>\n<pre>  + azurerm_resource_group.rg<br>      id:       &lt;computed&gt;<br>      location: \"westus2\"<br>      name:     \"myTFResourceGroup\"<br>      tags.%:   &lt;computed&gt;<br></pre>\n<pre>Plan: 1 to add, 0 to change, 0 to destroy.</pre>\n<pre>Do you want to perform these actions?<br>  Terraform will perform the actions described above.<br>  Only 'yes' will be accepted to approve.</pre>\n<pre>  ...</pre>\n<p>When Terraform created the resource group it also wrote data into the terraform.tfstate file. <a href=\"https://www.terraform.io/docs/state/index.html\">State</a> keeps track of the IDs of created resources so that Terraform knows what it is managing. You can inspect the current state using terraform state\u00a0show</p>\n<p>As we discussed earlier Terraform also comes up with features to maintain the entire life-cycle of the Infrastructure which makes it more powerful. Terraform was built to help manage and enact that change. As you change Terraform configurations, Terraform builds an execution plan that only modifies what is necessary to reach your desired\u00a0state.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/727/0*Piks8Tu6xUYpF4DU\"></figure><p><strong>Follow us on </strong><a href=\"https://twitter.com/joinfaun\"><strong>Twitter</strong></a><strong> </strong>\ud83d\udc26<strong> and </strong><a href=\"https://www.facebook.com/faun.dev/\"><strong>Facebook</strong></a><strong> </strong>\ud83d\udc65<strong> and join our </strong><a href=\"https://www.facebook.com/groups/364904580892967/\"><strong>Facebook Group</strong></a><strong>\u00a0</strong>\ud83d\udcac<strong>.</strong></p>\n<p><strong>To join our community Slack </strong>\ud83d\udde3\ufe0f <strong>and read our weekly Faun topics </strong>\ud83d\uddde\ufe0f,<strong> click\u00a0here\u2b07</strong></p>\n<figure><a href=\"https://www.faun.dev/join/?utm_source=medium.com%2Ffaun&amp;utm_medium=medium&amp;utm_campaign=faunmediumbanner\"><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*oSdFkACJxs5iy1oR\"></a></figure><h4>If this post was helpful, please click the clap \ud83d\udc4f button below a few times to show your support for the author!\u00a0\u2b07</h4>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=2e429e9a2277\" width=\"1\" height=\"1\"><hr>\n<p><a href=\"https://medium.com/faun/getting-started-with-terraform-and-infrastructure-as-code-2e429e9a2277\">Getting Started with Terraform and Infrastructure as Code</a> was originally published in <a href=\"https://medium.com/faun\">Faun</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
            "content": "\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*g_gzQiegpNUliVRZ\"><figcaption>Photo by <a href=\"https://unsplash.com/@_m_v_?utm_source=medium&amp;utm_medium=referral\">_M_V_</a> on\u00a0<a href=\"https://unsplash.com/?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p>Why do people really cares about Infrastructure Management/Automation? Before answering the question, lets start with this\u00a0: <em>How is infrastructure traditionally managed?</em></p>\n<p>In early ages I\u2019m a consumer of infrastructure, I would file a ticket, and then someone on the other end of this ticketing queue is pulling it off, logging it into a management portal or an administrative console, and pointing and clicking to provision that piece of infrastructure.</p>\n<p>This is fine provided the requirements are minimal. What if it comes to more complex requirements in multiple environments?</p>\n<blockquote>Infrastructure as Code evolved to solve the problem of <em>environment drift</em> in the release pipeline. Without IaC, teams must maintain the settings of individual deployment environments.</blockquote>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/600/1*gI7nYpjtjhiGChbOwuxZVA.png\"><figcaption>Infrastructure as Code\u00a0(IaC)</figcaption></figure><p>Lets conclude the benefits\u00a0as..</p>\n<ul>\n<li>Infrastructure as Code enables DevOps teams to test applications in production-like environments early in the development cycle.</li>\n<li>You can repeatedly deploy your solution throughout the development lifecycle and have confidence your resources are deployed in a consistent state.</li>\n<li>You can define the dependencies between resources so they\u2019re deployed in the correct\u00a0order.</li>\n</ul>\n<h4>Here comes Terraform\u2026</h4>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/472/1*rmwpOy4OtvgVz3yJvBetuQ.png\"><figcaption>Terraform</figcaption></figure><blockquote>Terraform is an opensource tool that codifies APIs into declarative configuration files that can be shared among team members, treated as code, edited, reviewed, and versioned.</blockquote>\n<p>For one, the configuration management tools, like Chef and Puppet, Terraform uses provisioners to set up resources, such as network, instances, and other things within the cloud platform. Since Terraform operates at this higher, abstract level than the other platforms, it provides a way for Terraform to work alongside or in place of those other\u00a0tools.</p>\n<h4>Terraform Approach</h4>\n<p>It gives it the ability, as a very lightweight executable, to take the place of any of the other ones, or simply work within the pipeline of a Chef automation, or a Puppet automation, of infrastructure. In relation to CloudFormation, the differences start out with cross platform and multi-cloud platform capabilities being a strong point in Terraform and relatively impossible to do multi-cloud in ARM Templates, because it\u2019s a propriety Azure only infrastructure tool.</p>\n<p>Heterogeneous infrastructure, frequently provisioned, short lived, and automated provisioning on-demand.</p>\n<ul>\n<li>Infrastructure as\u00a0code</li>\n<li>Embrace diversity with providers</li>\n<li>Enable self-service infrastructure</li>\n</ul>\n<p><strong>A quick look into Terraform workflow</strong></p>\n<p>The terraform <strong>Providers</strong> leverage infrastructure specific API to preserve unique capability for each providers. All these are unique and distinct.<em> It also comes up with custom resources for every cloud, but single consistent workflow to manage multiple cloud and services.</em></p>\n<p>The code given below is in HashiCorp Configuration Language (HCL). HCL is a structured language created with DevOps in mind; it is machine-friendly yet easy for humans to read, and it supports comments.</p>\n<a href=\"https://medium.com/media/dead3812189592313f0e9402a3625860/href\">https://medium.com/media/dead3812189592313f0e9402a3625860/href</a><p>The provider block is used to configure the named provider, in this instance the <a href=\"https://www.terraform.io/docs/providers/azurerm/index.html\">Azure provider</a>(azurerm). The Azure provider is responsible for creating and managing resources on\u00a0Azure.</p>\n<p>The <strong>terraform resource</strong> block defines a resource that exists within the infrastructure. A resource might be a physical component such as a network interface, or it can be a logical resource such as a Heroku application.</p>\n<a href=\"https://medium.com/media/a043ddd03d23c5882d275f2dde2c7b64/href\">https://medium.com/media/a043ddd03d23c5882d275f2dde2c7b64/href</a><p>The first command to run for a new configuration is terraform init, which initializes various local settings and data that will be used by subsequent commands. The terraform plan command is used to create an execution plan. Terraform performs a refresh, unless explicitly disabled, and then determines what actions are necessary to achieve the desired state specified in the configuration files.</p>\n<p>Next command terraform apply will shows the execution plan, describing which actions Terraform will take in order to change real infrastructure to match the configuration. The output format is similar to the diff format generated by tools such as Git. If the plan was created successfully, Terraform will now pause and wait for approval before proceeding.</p>\n<pre>sonu.jose@Azure:~/test$ terraform apply</pre>\n<pre>An execution plan has been generated and is shown below.<br>Resource actions are indicated with the following symbols:<br>  + create</pre>\n<pre>Terraform will perform the following actions:</pre>\n<pre>  + azurerm_resource_group.rg<br>      id:       &lt;computed&gt;<br>      location: \"westus2\"<br>      name:     \"myTFResourceGroup\"<br>      tags.%:   &lt;computed&gt;<br></pre>\n<pre>Plan: 1 to add, 0 to change, 0 to destroy.</pre>\n<pre>Do you want to perform these actions?<br>  Terraform will perform the actions described above.<br>  Only 'yes' will be accepted to approve.</pre>\n<pre>  ...</pre>\n<p>When Terraform created the resource group it also wrote data into the terraform.tfstate file. <a href=\"https://www.terraform.io/docs/state/index.html\">State</a> keeps track of the IDs of created resources so that Terraform knows what it is managing. You can inspect the current state using terraform state\u00a0show</p>\n<p>As we discussed earlier Terraform also comes up with features to maintain the entire life-cycle of the Infrastructure which makes it more powerful. Terraform was built to help manage and enact that change. As you change Terraform configurations, Terraform builds an execution plan that only modifies what is necessary to reach your desired\u00a0state.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/727/0*Piks8Tu6xUYpF4DU\"></figure><p><strong>Follow us on </strong><a href=\"https://twitter.com/joinfaun\"><strong>Twitter</strong></a><strong> </strong>\ud83d\udc26<strong> and </strong><a href=\"https://www.facebook.com/faun.dev/\"><strong>Facebook</strong></a><strong> </strong>\ud83d\udc65<strong> and join our </strong><a href=\"https://www.facebook.com/groups/364904580892967/\"><strong>Facebook Group</strong></a><strong>\u00a0</strong>\ud83d\udcac<strong>.</strong></p>\n<p><strong>To join our community Slack </strong>\ud83d\udde3\ufe0f <strong>and read our weekly Faun topics </strong>\ud83d\uddde\ufe0f,<strong> click\u00a0here\u2b07</strong></p>\n<figure><a href=\"https://www.faun.dev/join/?utm_source=medium.com%2Ffaun&amp;utm_medium=medium&amp;utm_campaign=faunmediumbanner\"><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*oSdFkACJxs5iy1oR\"></a></figure><h4>If this post was helpful, please click the clap \ud83d\udc4f button below a few times to show your support for the author!\u00a0\u2b07</h4>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=2e429e9a2277\" width=\"1\" height=\"1\"><hr>\n<p><a href=\"https://medium.com/faun/getting-started-with-terraform-and-infrastructure-as-code-2e429e9a2277\">Getting Started with Terraform and Infrastructure as Code</a> was originally published in <a href=\"https://medium.com/faun\">Faun</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
            "enclosure": {},
            "categories": [
                "devops",
                "cloud-computing",
                "software-development",
                "software-engineering",
                "terraform"
            ]
        },
        {
            "title": "What it means to be Cloud-Native approach\u200a\u2014\u200athe CNCF way",
            "pubDate": "2019-04-07 20:07:21",
            "link": "https://medium.com/developingnodes/what-it-means-to-be-cloud-native-approach-the-cncf-way-9e8ab99d4923?source=rss-e9f19c1a98fb------2",
            "guid": "https://medium.com/p/9e8ab99d4923",
            "author": "Sonu Jose",
            "thumbnail": "https://cdn-images-1.medium.com/max/2600/0*YknjM7T_Pxwz9deR",
            "description": "<div class=\"medium-feed-item\">\n<p class=\"medium-feed-image\"><a href=\"https://medium.com/developingnodes/what-it-means-to-be-cloud-native-approach-the-cncf-way-9e8ab99d4923?source=rss-e9f19c1a98fb------2\"><img src=\"https://cdn-images-1.medium.com/max/2600/0*YknjM7T_Pxwz9deR\" width=\"3882\"></a></p>\n<p class=\"medium-feed-snippet\">Michael Dell once said that \u201cthe cloud isn\u2019t a place, it\u2019s a way of doing IT\u201d. He was right, and the same can be said of cloud-native.</p>\n<p class=\"medium-feed-link\"><a href=\"https://medium.com/developingnodes/what-it-means-to-be-cloud-native-approach-the-cncf-way-9e8ab99d4923?source=rss-e9f19c1a98fb------2\">Continue reading on DevelopingNodes \u00bb</a></p>\n</div>",
            "content": "<div class=\"medium-feed-item\">\n<p class=\"medium-feed-image\"><a href=\"https://medium.com/developingnodes/what-it-means-to-be-cloud-native-approach-the-cncf-way-9e8ab99d4923?source=rss-e9f19c1a98fb------2\"><img src=\"https://cdn-images-1.medium.com/max/2600/0*YknjM7T_Pxwz9deR\" width=\"3882\"></a></p>\n<p class=\"medium-feed-snippet\">Michael Dell once said that \u201cthe cloud isn\u2019t a place, it\u2019s a way of doing IT\u201d. He was right, and the same can be said of cloud-native.</p>\n<p class=\"medium-feed-link\"><a href=\"https://medium.com/developingnodes/what-it-means-to-be-cloud-native-approach-the-cncf-way-9e8ab99d4923?source=rss-e9f19c1a98fb------2\">Continue reading on DevelopingNodes \u00bb</a></p>\n</div>",
            "enclosure": {},
            "categories": [
                "cloud-native",
                "kubernetes",
                "cloud-computing",
                "docker",
                "microservices"
            ]
        },
        {
            "title": "Setting up kubernetes cluster on raspberry pi",
            "pubDate": "2019-03-30 09:48:22",
            "link": "https://medium.com/developingnodes/setting-up-kubernetes-cluster-on-raspberry-pi-15cc44f404b5?source=rss-e9f19c1a98fb------2",
            "guid": "https://medium.com/p/15cc44f404b5",
            "author": "Sonu Jose",
            "thumbnail": "https://cdn-images-1.medium.com/max/1024/0*GAatTrbdwkx5nwxi",
            "description": "\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*GAatTrbdwkx5nwxi\"><figcaption>Photo by <a href=\"https://unsplash.com/@hbtography?utm_source=medium&amp;utm_medium=referral\">Harrison Broadbent</a> on\u00a0<a href=\"https://unsplash.com/?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p>This article is all about the steps needed to setup a k8s cluster on a raspberry pi. And Yes\u200a\u2014\u200ayou can create a Kubernetes cluster with Raspberry Pis with the default operating system Raspbian. This means you can carry on using all the tools and packages you\u2019re used to with the officially-supported OS.</p>\n<h4>Pre-reqs:</h4>\n<ul>\n<li>You must use an RPi 2 or 3 for use with Kubernetes</li>\n<li>I\u2019m assuming you\u2019re using wired ethernet (Wi-Fi also works, but it\u2019s not recommended)</li>\n<li>You must have a Raspbean OS running on yout raspberry pi (Raspbian Jessie recommented)</li>\n</ul>\n<p><a href=\"https://www.raspberrypi.org/downloads/raspbian/\">Download Raspbian for Raspberry Pi</a></p>\n<h4>Lets talk a bit on kubernetes (k8s)</h4>\n<p>Kubernetes is a powerful open-source system, initially developed by Google, for managing containerized applications in a clustered environment. It aims to provide better ways of managing related, distributed components and services across varied infrastructure.</p>\n<p>At its basic level, k8s is a system for running and coordinating containerized applications across a cluster of machines. It is a platform designed to completely manage the life cycle of containerized applications and services using methods that provide predictability, scalability, and high availability.</p>\n<p>The picture shown below gives some idea of the architecture of a kubernetes system.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/800/1*bqTigPV3yvLpKwsrdRlI6g.jpeg\"></figure><h3>Master node\u00a0setup</h3>\n<ul><li>Change hostname</li></ul>\n<p>Use the raspi-config utility to change the hostname to k8s-master-1 or similar and then\u00a0reboot.</p>\n<ul><li>Set a static IP\u00a0address</li></ul>\n<p>It\u2019s not fun when your cluster breaks because the IP of your master changed. The master\u2019s certificates will be bound to the IP address, so let\u2019s fix that problem ahead of\u00a0time:</p>\n<pre>cat &gt;&gt; /etc/dhcpcd.conf</pre>\n<p>Paste this\u00a0block:</p>\n<pre>profile static_eth0<br>static ip_address=192.168.0.100/24<br>static routers=192.168.0.1<br>static domain_name_servers=8.8.8.8</pre>\n<p>Hit Control +\u00a0D.</p>\n<p>Change 100 for 101, 102, 103\u00a0etc.</p>\n<p>You may also need to make a reservation on your router\u2019s DHCP table so these addresses don\u2019t get given out to other devices on your\u00a0network.</p>\n<ul><li>Install Docker Take care while installing docker, ned to make sure the latest verified docker version by kubernetes, here i am adding code for bth downloadng latest version as well as specified version (I spend a lot time figuring out the version mismatch\u00a0issue)</li></ul>\n<p>Use the specified docker\u00a0version</p>\n<pre>export VERSION=18.03 &amp;&amp; curl -sSL get.docker.com | sh &amp;&amp; \\<br>sudo usermod pi -aG docker</pre>\n<p>Download the latest docker\u00a0version</p>\n<pre>$ curl -sSL get.docker.com | sh &amp;&amp; \\<br>sudo usermod pi -aG docker<br>newgrp docker</pre>\n<ul><li>Disable swap</li></ul>\n<p>For Kubernetes 1.7 and onwards you will get an error if swap space is\u00a0enabled.</p>\n<p>Turn off\u00a0swap:</p>\n<pre>$ sudo dphys-swapfile swapoff &amp;&amp; \\<br>  sudo dphys-swapfile uninstall &amp;&amp; \\<br>  sudo update-rc.d dphys-swapfile remove</pre>\n<p>This should now show no\u00a0entries:</p>\n<pre>$ sudo swapon --summary</pre>\n<ul><li>Edit /boot/cmdline.txt</li></ul>\n<p>Add this text at the end of the line, but don\u2019t create any new\u00a0lines:</p>\n<p>You can use vim (or any editor of you choice\u00a0(nano))</p>\n<pre>sudo vim /boot/cmdline.txt</pre>\n<pre>cgroup_enable=cpuset cgroup_memory=1 cgroup_enable=memory</pre>\n<p>Now reboot\u200a\u2014\u200ado not skip this\u00a0step.</p>\n<ul><li>Add repo lists &amp; install\u00a0kubeadm</li></ul>\n<pre>$ curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add - &amp;&amp; \\<br>  echo \"deb http://apt.kubernetes.io/ kubernetes-xenial main\" | sudo tee /etc/apt/sources.list.d/kubernetes.list &amp;&amp; \\<br>  sudo apt-get update -q &amp;&amp; \\<br>  sudo apt-get install -qy kubeadm</pre>\n<blockquote><em>I realise this says \u2018xenial\u2019 in the apt listing, don\u2019t worry. It still\u00a0works.</em></blockquote>\n<h3>Initialize your master\u00a0node</h3>\n<ul>\n<li>You now have two new commands installed:</li>\n<li>kubeadm\u200a\u2014\u200aused to create new clusters or join an existing\u00a0one</li>\n<li>kubectl\u200a\u2014\u200athe CLI administration tool for Kubernetes</li>\n</ul>\n<p>If using Weave\u00a0Net</p>\n<ul><li>Initialize your master\u00a0node:</li></ul>\n<pre>$ sudo kubeadm init --token-ttl=0</pre>\n<p>If using\u00a0Flannel:</p>\n<ul><li>Initialize your master node with a Pod network\u00a0CIDR:</li></ul>\n<pre>$ sudo kubeadm init --token-ttl=0 --pod-network-cidr=10.244.0.0/16</pre>\n<p>We pass in --token-ttl=0 so that the token never expires - do not use this setting in production. The UX for kubeadmmeans it's currently very hard to get a join token later on after the initial token has\u00a0expired.</p>\n<blockquote>\n<em>Optionally also pass </em><em>--apiserver-advertise-address=192.168.0.27 with the IP of the Pi as found by typing </em><em>ifconfig.</em>\n</blockquote>\n<p>Note: This step can take a long time, even up to 15\u00a0minutes.</p>\n<p>Sometimes this stage can fail, if it does then you should patch the API Server to allow for a higher failure threshold during initialization around the time you see [controlplane] wrote Static Pod manifest for component kube-apiserver to \"/etc/kubernetes/manifests/kube-apiserver.yaml\"</p>\n<pre>sudo sed -i 's/failureThreshold: 8/failureThreshold: 20/g' /etc/kubernetes/manifests/kube-apiserver.yaml</pre>\n<p>After the init is complete run the snippet given to you on the command-line:</p>\n<pre>mkdir -p $HOME/.kube<br>  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config<br>  sudo chown $(id -u):$(id -g) $HOME/.kube/config</pre>\n<p>This step takes the key generated for cluster administration and makes it available in a default location for use with\u00a0kubectl.</p>\n<ul><li>Now save your join-token</li></ul>\n<p>Your join token is valid for 24 hours, so save it into a text file. Here\u2019s an example of\u00a0mine:</p>\n<pre>$ kubeadm join --token 9e700f.7dc97f5e3a45c9e5 192.168.0.27:6443 --discovery-token-ca-cert-hash sha256:95cbb9ee5536aa61ec0239d6edd8598af68758308d0a0425848ae1af28859bea</pre>\n<ul><li>Check everything worked:</li></ul>\n<pre>$ kubectl get pods --namespace=kube-system<br>NAME                                  READY   STATUS    RESTARTS   AGE<br>coredns-576cbf47c7-n85xt              1/1     Running   0          6m25s<br>coredns-576cbf47c7-rq6lc              1/1     Running   0          6m25s<br>etcd-raspberrypi                      1/1     Running   0          5m55s<br>kube-apiserver-raspberrypi            1/1     Running   1          7m57s<br>kube-controller-manager-raspberrypi   1/1     Running   0          7m58s<br>kube-proxy-w26jz                      1/1     Running   0          6m25s<br>kube-scheduler-raspberrypi            1/1     Running   0          5m47s<br>weave-net-wdq4f                       2/2     Running   0          2m39s</pre>\n<p>You should see the \u201cREADY\u201d count showing as 1/1 for all services as above. DNS uses three pods, so you\u2019ll see 3/3 for\u00a0that.</p>\n<h3>Setup networking with Weave Net or\u00a0Flannel</h3>\n<p>Some users have reported stability issues with Weave Net on ARMHF. These issues do not appear to affect x86_64 (regular PCs/VMs). You may want to try Flannel instead of Weave Net for your RPi\u00a0cluster.</p>\n<h4>Weave Net</h4>\n<p>Install <a href=\"https://www.weave.works/oss/net/\">Weave Net</a> network\u00a0driver</p>\n<pre>$ kubectl apply -f \\<br> \"https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\\n')\"</pre>\n<p>If you run into any issues with Weaveworks\u2019 networking then <a href=\"https://github.com/coreos/flannel\">flannel</a> is also a popular choice for the ARM platform.</p>\n<h4>Flannel (alternative)</h4>\n<p>Apply the Flannel driver on the\u00a0master:</p>\n<pre>$ kubectl apply -f <a href=\"https://raw.githubusercontent.com/coreos/flannel/c5d10c8/Documentation/kube-flannel.yml\">https://raw.githubusercontent.com/coreos/flannel/c5d10c8/Documentation/kube-flannel.yml</a></pre>\n<p>On each node that joins including the\u00a0master:</p>\n<pre>$ sudo sysctl net.bridge.bridge-nf-call-iptables=1</pre>\n<h4>Adding Worker\u00a0Nodes</h4>\n<p>On the other RPis, repeat everything apart from kubeadm\u00a0init.</p>\n<ul><li>Change hostname</li></ul>\n<p>Use the raspi-config utility to change the hostname to k8s-worker-1 or similar and then\u00a0reboot.</p>\n<ul><li>Join the\u00a0cluster</li></ul>\n<p>Replace the token / IP for the output you got from the master node, for\u00a0example:</p>\n<pre>$ sudo kubeadm join --token 1fd0d8.67e7083ed7ec08f3 192.168.0.27:6443</pre>\n<p>You can now run this on the\u00a0master:</p>\n<pre>$ kubectl get nodes<br>NAME      STATUS     AGE       VERSION<br>k8s-1     Ready      5m        v1.7.4<br>k8s-2     Ready      10m       v1.7.4</pre>\n<h3>Deploy a container</h3>\n<p>This container will expose a HTTP port and convert Markdown to HTML. Just post a body to it via curl - follow the instructions below.</p>\n<p><em>function.yml</em></p>\n<pre>apiVersion: v1<br>kind: Service<br>metadata:<br>  name: markdownrender<br>  labels:<br>    app: markdownrender<br>spec:<br>  type: NodePort<br>  ports:<br>    - port: 8080<br>      protocol: TCP<br>      targetPort: 8080<br>      nodePort: 31118<br>  selector:<br>    app: markdownrender<br>---<br>apiVersion: apps/v1beta1 # for versions before 1.6.0 use extensions/v1beta1<br>kind: Deployment<br>metadata:<br>  name: markdownrender<br>spec:<br>  replicas: 1<br>  template:<br>    metadata:<br>      labels:<br>        app: markdownrender<br>    spec:<br>      containers:<br>      - name: markdownrender<br>        image: functions/markdownrender:latest-armhf<br>        imagePullPolicy: Always<br>        ports:<br>        - containerPort: 8080<br>          protocol: TCP</pre>\n<p>Deploy and\u00a0test:</p>\n<pre>$ kubectl create -f function.yml</pre>\n<p>Once the Docker image has been pulled from the hub and the Pod is running you can access it via\u00a0curl:</p>\n<pre>$ curl -4 http://127.0.0.1:31118 -d \"# test\"<br>&lt;p&gt;&lt;h1&gt;test&lt;/h1&gt;&lt;/p&gt;</pre>\n<p>If you want to call the service from a remote machine such as your laptop then use the IP address of your Kubernetes master node and try the same\u00a0again.</p>\n<h3>Start up the Kubernetes dashboard</h3>\n<p>The dashboard can be useful for visualising the state and health of your system, but it does require the equivalent of \u201croot\u201d in the cluster. If you want to proceed you should first run in a <a href=\"https://github.com/kubernetes/dashboard/wiki/Access-control#admin-privileges\">ClusterRole from the\u00a0docs</a>.</p>\n<pre>echo -n 'apiVersion: rbac.authorization.k8s.io/v1beta1<br>kind: ClusterRoleBinding<br>metadata:<br>  name: kubernetes-dashboard<br>  labels:<br>    k8s-app: kubernetes-dashboard<br>roleRef:<br>  apiGroup: rbac.authorization.k8s.io<br>  kind: ClusterRole<br>  name: cluster-admin<br>subjects:<br>- kind: ServiceAccount<br>  name: kubernetes-dashboard<br>  namespace: kube-system' | kubectl apply -f -</pre>\n<p>This is the development/alternative dashboard which has TLS disabled and is easier to\u00a0use.</p>\n<pre>$ kubectl apply -f <a href=\"https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/alternative/kubernetes-dashboard-arm.yaml\">https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/alternative/kubernetes-dashboard-arm.yaml</a></pre>\n<p>You can then find the IP and port via kubectl get svc -n kube-system. To access this from your laptop you will need to use kubectl proxy and navigate to http://localhost:8001/ on the master, or tunnel to this address with\u00a0ssh.</p>\n<p>See also: <a href=\"https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/\">Kubernetes Dashboard</a> docs.</p>\n<h4>Summary</h4>\n<p>You should now have an operational Kubernetes master and several worker nodes ready to accept workloads.</p>\n<p>Now let\u2019s head back <a href=\"https://blog.alexellis.io/serverless-kubernetes-on-raspberry-pi/\">over to the tutorial and deploy OpenFaaS</a> to put the cluster through its paces with Serverless functions.</p>\n<p>See also: <a href=\"https://kubernetes.io/docs/home/?path=users&amp;persona=app-developer&amp;level=foundational\">Kubernetes documentation</a></p>\n<p>You can find the automated scripts and other necessary at\u00a0: <a href=\"https://github.com/sonujose/kubernetes_raspberrypi\"><em>https://github.com/sonujose/kubernetes_raspberrypi</em></a></p>\n<p>Long live Kubernetes\u2026</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=15cc44f404b5\" width=\"1\" height=\"1\"><hr>\n<p><a href=\"https://medium.com/developingnodes/setting-up-kubernetes-cluster-on-raspberry-pi-15cc44f404b5\">Setting up kubernetes cluster on raspberry pi</a> was originally published in <a href=\"https://medium.com/developingnodes\">DevelopingNodes</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
            "content": "\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*GAatTrbdwkx5nwxi\"><figcaption>Photo by <a href=\"https://unsplash.com/@hbtography?utm_source=medium&amp;utm_medium=referral\">Harrison Broadbent</a> on\u00a0<a href=\"https://unsplash.com/?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p>This article is all about the steps needed to setup a k8s cluster on a raspberry pi. And Yes\u200a\u2014\u200ayou can create a Kubernetes cluster with Raspberry Pis with the default operating system Raspbian. This means you can carry on using all the tools and packages you\u2019re used to with the officially-supported OS.</p>\n<h4>Pre-reqs:</h4>\n<ul>\n<li>You must use an RPi 2 or 3 for use with Kubernetes</li>\n<li>I\u2019m assuming you\u2019re using wired ethernet (Wi-Fi also works, but it\u2019s not recommended)</li>\n<li>You must have a Raspbean OS running on yout raspberry pi (Raspbian Jessie recommented)</li>\n</ul>\n<p><a href=\"https://www.raspberrypi.org/downloads/raspbian/\">Download Raspbian for Raspberry Pi</a></p>\n<h4>Lets talk a bit on kubernetes (k8s)</h4>\n<p>Kubernetes is a powerful open-source system, initially developed by Google, for managing containerized applications in a clustered environment. It aims to provide better ways of managing related, distributed components and services across varied infrastructure.</p>\n<p>At its basic level, k8s is a system for running and coordinating containerized applications across a cluster of machines. It is a platform designed to completely manage the life cycle of containerized applications and services using methods that provide predictability, scalability, and high availability.</p>\n<p>The picture shown below gives some idea of the architecture of a kubernetes system.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/800/1*bqTigPV3yvLpKwsrdRlI6g.jpeg\"></figure><h3>Master node\u00a0setup</h3>\n<ul><li>Change hostname</li></ul>\n<p>Use the raspi-config utility to change the hostname to k8s-master-1 or similar and then\u00a0reboot.</p>\n<ul><li>Set a static IP\u00a0address</li></ul>\n<p>It\u2019s not fun when your cluster breaks because the IP of your master changed. The master\u2019s certificates will be bound to the IP address, so let\u2019s fix that problem ahead of\u00a0time:</p>\n<pre>cat &gt;&gt; /etc/dhcpcd.conf</pre>\n<p>Paste this\u00a0block:</p>\n<pre>profile static_eth0<br>static ip_address=192.168.0.100/24<br>static routers=192.168.0.1<br>static domain_name_servers=8.8.8.8</pre>\n<p>Hit Control +\u00a0D.</p>\n<p>Change 100 for 101, 102, 103\u00a0etc.</p>\n<p>You may also need to make a reservation on your router\u2019s DHCP table so these addresses don\u2019t get given out to other devices on your\u00a0network.</p>\n<ul><li>Install Docker Take care while installing docker, ned to make sure the latest verified docker version by kubernetes, here i am adding code for bth downloadng latest version as well as specified version (I spend a lot time figuring out the version mismatch\u00a0issue)</li></ul>\n<p>Use the specified docker\u00a0version</p>\n<pre>export VERSION=18.03 &amp;&amp; curl -sSL get.docker.com | sh &amp;&amp; \\<br>sudo usermod pi -aG docker</pre>\n<p>Download the latest docker\u00a0version</p>\n<pre>$ curl -sSL get.docker.com | sh &amp;&amp; \\<br>sudo usermod pi -aG docker<br>newgrp docker</pre>\n<ul><li>Disable swap</li></ul>\n<p>For Kubernetes 1.7 and onwards you will get an error if swap space is\u00a0enabled.</p>\n<p>Turn off\u00a0swap:</p>\n<pre>$ sudo dphys-swapfile swapoff &amp;&amp; \\<br>  sudo dphys-swapfile uninstall &amp;&amp; \\<br>  sudo update-rc.d dphys-swapfile remove</pre>\n<p>This should now show no\u00a0entries:</p>\n<pre>$ sudo swapon --summary</pre>\n<ul><li>Edit /boot/cmdline.txt</li></ul>\n<p>Add this text at the end of the line, but don\u2019t create any new\u00a0lines:</p>\n<p>You can use vim (or any editor of you choice\u00a0(nano))</p>\n<pre>sudo vim /boot/cmdline.txt</pre>\n<pre>cgroup_enable=cpuset cgroup_memory=1 cgroup_enable=memory</pre>\n<p>Now reboot\u200a\u2014\u200ado not skip this\u00a0step.</p>\n<ul><li>Add repo lists &amp; install\u00a0kubeadm</li></ul>\n<pre>$ curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add - &amp;&amp; \\<br>  echo \"deb http://apt.kubernetes.io/ kubernetes-xenial main\" | sudo tee /etc/apt/sources.list.d/kubernetes.list &amp;&amp; \\<br>  sudo apt-get update -q &amp;&amp; \\<br>  sudo apt-get install -qy kubeadm</pre>\n<blockquote><em>I realise this says \u2018xenial\u2019 in the apt listing, don\u2019t worry. It still\u00a0works.</em></blockquote>\n<h3>Initialize your master\u00a0node</h3>\n<ul>\n<li>You now have two new commands installed:</li>\n<li>kubeadm\u200a\u2014\u200aused to create new clusters or join an existing\u00a0one</li>\n<li>kubectl\u200a\u2014\u200athe CLI administration tool for Kubernetes</li>\n</ul>\n<p>If using Weave\u00a0Net</p>\n<ul><li>Initialize your master\u00a0node:</li></ul>\n<pre>$ sudo kubeadm init --token-ttl=0</pre>\n<p>If using\u00a0Flannel:</p>\n<ul><li>Initialize your master node with a Pod network\u00a0CIDR:</li></ul>\n<pre>$ sudo kubeadm init --token-ttl=0 --pod-network-cidr=10.244.0.0/16</pre>\n<p>We pass in --token-ttl=0 so that the token never expires - do not use this setting in production. The UX for kubeadmmeans it's currently very hard to get a join token later on after the initial token has\u00a0expired.</p>\n<blockquote>\n<em>Optionally also pass </em><em>--apiserver-advertise-address=192.168.0.27 with the IP of the Pi as found by typing </em><em>ifconfig.</em>\n</blockquote>\n<p>Note: This step can take a long time, even up to 15\u00a0minutes.</p>\n<p>Sometimes this stage can fail, if it does then you should patch the API Server to allow for a higher failure threshold during initialization around the time you see [controlplane] wrote Static Pod manifest for component kube-apiserver to \"/etc/kubernetes/manifests/kube-apiserver.yaml\"</p>\n<pre>sudo sed -i 's/failureThreshold: 8/failureThreshold: 20/g' /etc/kubernetes/manifests/kube-apiserver.yaml</pre>\n<p>After the init is complete run the snippet given to you on the command-line:</p>\n<pre>mkdir -p $HOME/.kube<br>  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config<br>  sudo chown $(id -u):$(id -g) $HOME/.kube/config</pre>\n<p>This step takes the key generated for cluster administration and makes it available in a default location for use with\u00a0kubectl.</p>\n<ul><li>Now save your join-token</li></ul>\n<p>Your join token is valid for 24 hours, so save it into a text file. Here\u2019s an example of\u00a0mine:</p>\n<pre>$ kubeadm join --token 9e700f.7dc97f5e3a45c9e5 192.168.0.27:6443 --discovery-token-ca-cert-hash sha256:95cbb9ee5536aa61ec0239d6edd8598af68758308d0a0425848ae1af28859bea</pre>\n<ul><li>Check everything worked:</li></ul>\n<pre>$ kubectl get pods --namespace=kube-system<br>NAME                                  READY   STATUS    RESTARTS   AGE<br>coredns-576cbf47c7-n85xt              1/1     Running   0          6m25s<br>coredns-576cbf47c7-rq6lc              1/1     Running   0          6m25s<br>etcd-raspberrypi                      1/1     Running   0          5m55s<br>kube-apiserver-raspberrypi            1/1     Running   1          7m57s<br>kube-controller-manager-raspberrypi   1/1     Running   0          7m58s<br>kube-proxy-w26jz                      1/1     Running   0          6m25s<br>kube-scheduler-raspberrypi            1/1     Running   0          5m47s<br>weave-net-wdq4f                       2/2     Running   0          2m39s</pre>\n<p>You should see the \u201cREADY\u201d count showing as 1/1 for all services as above. DNS uses three pods, so you\u2019ll see 3/3 for\u00a0that.</p>\n<h3>Setup networking with Weave Net or\u00a0Flannel</h3>\n<p>Some users have reported stability issues with Weave Net on ARMHF. These issues do not appear to affect x86_64 (regular PCs/VMs). You may want to try Flannel instead of Weave Net for your RPi\u00a0cluster.</p>\n<h4>Weave Net</h4>\n<p>Install <a href=\"https://www.weave.works/oss/net/\">Weave Net</a> network\u00a0driver</p>\n<pre>$ kubectl apply -f \\<br> \"https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\\n')\"</pre>\n<p>If you run into any issues with Weaveworks\u2019 networking then <a href=\"https://github.com/coreos/flannel\">flannel</a> is also a popular choice for the ARM platform.</p>\n<h4>Flannel (alternative)</h4>\n<p>Apply the Flannel driver on the\u00a0master:</p>\n<pre>$ kubectl apply -f <a href=\"https://raw.githubusercontent.com/coreos/flannel/c5d10c8/Documentation/kube-flannel.yml\">https://raw.githubusercontent.com/coreos/flannel/c5d10c8/Documentation/kube-flannel.yml</a></pre>\n<p>On each node that joins including the\u00a0master:</p>\n<pre>$ sudo sysctl net.bridge.bridge-nf-call-iptables=1</pre>\n<h4>Adding Worker\u00a0Nodes</h4>\n<p>On the other RPis, repeat everything apart from kubeadm\u00a0init.</p>\n<ul><li>Change hostname</li></ul>\n<p>Use the raspi-config utility to change the hostname to k8s-worker-1 or similar and then\u00a0reboot.</p>\n<ul><li>Join the\u00a0cluster</li></ul>\n<p>Replace the token / IP for the output you got from the master node, for\u00a0example:</p>\n<pre>$ sudo kubeadm join --token 1fd0d8.67e7083ed7ec08f3 192.168.0.27:6443</pre>\n<p>You can now run this on the\u00a0master:</p>\n<pre>$ kubectl get nodes<br>NAME      STATUS     AGE       VERSION<br>k8s-1     Ready      5m        v1.7.4<br>k8s-2     Ready      10m       v1.7.4</pre>\n<h3>Deploy a container</h3>\n<p>This container will expose a HTTP port and convert Markdown to HTML. Just post a body to it via curl - follow the instructions below.</p>\n<p><em>function.yml</em></p>\n<pre>apiVersion: v1<br>kind: Service<br>metadata:<br>  name: markdownrender<br>  labels:<br>    app: markdownrender<br>spec:<br>  type: NodePort<br>  ports:<br>    - port: 8080<br>      protocol: TCP<br>      targetPort: 8080<br>      nodePort: 31118<br>  selector:<br>    app: markdownrender<br>---<br>apiVersion: apps/v1beta1 # for versions before 1.6.0 use extensions/v1beta1<br>kind: Deployment<br>metadata:<br>  name: markdownrender<br>spec:<br>  replicas: 1<br>  template:<br>    metadata:<br>      labels:<br>        app: markdownrender<br>    spec:<br>      containers:<br>      - name: markdownrender<br>        image: functions/markdownrender:latest-armhf<br>        imagePullPolicy: Always<br>        ports:<br>        - containerPort: 8080<br>          protocol: TCP</pre>\n<p>Deploy and\u00a0test:</p>\n<pre>$ kubectl create -f function.yml</pre>\n<p>Once the Docker image has been pulled from the hub and the Pod is running you can access it via\u00a0curl:</p>\n<pre>$ curl -4 http://127.0.0.1:31118 -d \"# test\"<br>&lt;p&gt;&lt;h1&gt;test&lt;/h1&gt;&lt;/p&gt;</pre>\n<p>If you want to call the service from a remote machine such as your laptop then use the IP address of your Kubernetes master node and try the same\u00a0again.</p>\n<h3>Start up the Kubernetes dashboard</h3>\n<p>The dashboard can be useful for visualising the state and health of your system, but it does require the equivalent of \u201croot\u201d in the cluster. If you want to proceed you should first run in a <a href=\"https://github.com/kubernetes/dashboard/wiki/Access-control#admin-privileges\">ClusterRole from the\u00a0docs</a>.</p>\n<pre>echo -n 'apiVersion: rbac.authorization.k8s.io/v1beta1<br>kind: ClusterRoleBinding<br>metadata:<br>  name: kubernetes-dashboard<br>  labels:<br>    k8s-app: kubernetes-dashboard<br>roleRef:<br>  apiGroup: rbac.authorization.k8s.io<br>  kind: ClusterRole<br>  name: cluster-admin<br>subjects:<br>- kind: ServiceAccount<br>  name: kubernetes-dashboard<br>  namespace: kube-system' | kubectl apply -f -</pre>\n<p>This is the development/alternative dashboard which has TLS disabled and is easier to\u00a0use.</p>\n<pre>$ kubectl apply -f <a href=\"https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/alternative/kubernetes-dashboard-arm.yaml\">https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/alternative/kubernetes-dashboard-arm.yaml</a></pre>\n<p>You can then find the IP and port via kubectl get svc -n kube-system. To access this from your laptop you will need to use kubectl proxy and navigate to http://localhost:8001/ on the master, or tunnel to this address with\u00a0ssh.</p>\n<p>See also: <a href=\"https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/\">Kubernetes Dashboard</a> docs.</p>\n<h4>Summary</h4>\n<p>You should now have an operational Kubernetes master and several worker nodes ready to accept workloads.</p>\n<p>Now let\u2019s head back <a href=\"https://blog.alexellis.io/serverless-kubernetes-on-raspberry-pi/\">over to the tutorial and deploy OpenFaaS</a> to put the cluster through its paces with Serverless functions.</p>\n<p>See also: <a href=\"https://kubernetes.io/docs/home/?path=users&amp;persona=app-developer&amp;level=foundational\">Kubernetes documentation</a></p>\n<p>You can find the automated scripts and other necessary at\u00a0: <a href=\"https://github.com/sonujose/kubernetes_raspberrypi\"><em>https://github.com/sonujose/kubernetes_raspberrypi</em></a></p>\n<p>Long live Kubernetes\u2026</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=15cc44f404b5\" width=\"1\" height=\"1\"><hr>\n<p><a href=\"https://medium.com/developingnodes/setting-up-kubernetes-cluster-on-raspberry-pi-15cc44f404b5\">Setting up kubernetes cluster on raspberry pi</a> was originally published in <a href=\"https://medium.com/developingnodes\">DevelopingNodes</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
            "enclosure": {},
            "categories": [
                "docker",
                "kubernetes",
                "raspberry-pi",
                "distributed-systems",
                "software-engineering"
            ]
        }
    ]
}